{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ettoday 網路爬蟲實作練習\n",
    "\n",
    "\n",
    "* 能夠利用 Request + BeatifulSour 撰寫爬蟲，並存放到合適的資料結構\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業目標\n",
    "\n",
    "根據範例：\n",
    "\n",
    "* 取出今天所有的新聞\n",
    "* 取出今天下午三點到五點的新聞\n",
    "* 根據範例，取出三天前下午三點到五點的新聞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 12, 23, 23, 59)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "today_date = datetime.datetime.now()\n",
    "today_date = datetime.datetime(today_date.year, today_date.month, today_date.day, 23, 59)\n",
    "today_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch browser in selenium webdriver\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "browser = webdriver.Chrome(executable_path='../chromedriver_win32/chromedriver.exe')\n",
    "browser.get(\"https://www.ettoday.net/news/news-list.htm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scroll down webpage every 2 seconds\n",
    "\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def scroll_all_news(date):\n",
    "    while(1):\n",
    "        time.sleep(0.6)\n",
    "        browser.execute_script(\"window.scrollTo(0, 50000);\")   \n",
    "\n",
    "        # check time\n",
    "        html_source = browser.page_source\n",
    "        soup = BeautifulSoup(html_source, \"html5lib\")\n",
    "        tag = soup.find(class_=\"part_list_2\").find_all('h3')[-1]\n",
    "        tag_date = tag.find(class_=\"date\").text\n",
    "        print(\"[scrolling...]\", tag_date)\n",
    "\n",
    "        p = re.compile(\"(\\d+)/(\\d+)/(\\d+) (\\d+):(\\d+)\")\n",
    "        m = p.match(tag_date)\n",
    "        if m:\n",
    "            post_date_Y = int(m.group(1))\n",
    "            post_date_m = int(m.group(2))\n",
    "            post_date_d = int(m.group(3))\n",
    "            post_date_H = int(m.group(4))\n",
    "            post_date_M = int(m.group(5))\n",
    "            \n",
    "            timedelta = date - datetime.datetime(post_date_Y, \n",
    "                                                 post_date_m,\n",
    "                                                 post_date_d,\n",
    "                                                 post_date_H,\n",
    "                                                 post_date_M)\n",
    "            if timedelta.days > 0:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 根據範例，取出今天所有的新聞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYour Code\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Your Code\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[scrolling...] 2019/12/23 19:07\n",
      "[scrolling...] 2019/12/23 19:07\n",
      "[scrolling...] 2019/12/23 19:07\n",
      "[scrolling...] 2019/12/23 19:07\n",
      "[scrolling...] 2019/12/23 19:07\n",
      "[scrolling...] 2019/12/23 18:56\n",
      "[scrolling...] 2019/12/23 18:27\n",
      "[scrolling...] 2019/12/23 17:58\n",
      "[scrolling...] 2019/12/23 17:52\n",
      "[scrolling...] 2019/12/23 17:45\n",
      "[scrolling...] 2019/12/23 17:38\n",
      "[scrolling...] 2019/12/23 17:29\n",
      "[scrolling...] 2019/12/23 17:22\n",
      "[scrolling...] 2019/12/23 17:12\n",
      "[scrolling...] 2019/12/23 17:04\n",
      "[scrolling...] 2019/12/23 16:57\n",
      "[scrolling...] 2019/12/23 16:48\n",
      "[scrolling...] 2019/12/23 16:40\n",
      "[scrolling...] 2019/12/23 16:25\n",
      "[scrolling...] 2019/12/23 16:12\n",
      "[scrolling...] 2019/12/23 16:05\n",
      "[scrolling...] 2019/12/23 15:58\n",
      "[scrolling...] 2019/12/23 15:45\n",
      "[scrolling...] 2019/12/23 15:34\n",
      "[scrolling...] 2019/12/23 15:18\n",
      "[scrolling...] 2019/12/23 15:08\n",
      "[scrolling...] 2019/12/23 14:52\n",
      "[scrolling...] 2019/12/23 14:41\n",
      "[scrolling...] 2019/12/23 14:33\n",
      "[scrolling...] 2019/12/23 14:14\n",
      "[scrolling...] 2019/12/23 14:01\n",
      "[scrolling...] 2019/12/23 13:38\n",
      "[scrolling...] 2019/12/23 13:26\n",
      "[scrolling...] 2019/12/23 13:16\n",
      "[scrolling...] 2019/12/23 13:07\n",
      "[scrolling...] 2019/12/23 12:56\n",
      "[scrolling...] 2019/12/23 12:40\n",
      "[scrolling...] 2019/12/23 12:30\n",
      "[scrolling...] 2019/12/23 12:23\n",
      "[scrolling...] 2019/12/23 12:12\n",
      "[scrolling...] 2019/12/23 12:05\n",
      "[scrolling...] 2019/12/23 12:00\n",
      "[scrolling...] 2019/12/23 11:47\n",
      "[scrolling...] 2019/12/23 11:37\n",
      "[scrolling...] 2019/12/23 11:30\n",
      "[scrolling...] 2019/12/23 11:19\n",
      "[scrolling...] 2019/12/23 11:09\n",
      "[scrolling...] 2019/12/23 11:01\n",
      "[scrolling...] 2019/12/23 10:53\n",
      "[scrolling...] 2019/12/23 10:46\n",
      "[scrolling...] 2019/12/23 10:28\n",
      "[scrolling...] 2019/12/23 10:11\n",
      "[scrolling...] 2019/12/23 09:56\n",
      "[scrolling...] 2019/12/23 09:28\n",
      "[scrolling...] 2019/12/23 09:04\n",
      "[scrolling...] 2019/12/23 08:31\n",
      "[scrolling...] 2019/12/23 07:11\n",
      "[scrolling...] 2019/12/23 05:51\n",
      "[scrolling...] 2019/12/23 01:49\n",
      "[scrolling...] 2019/12/23 00:31\n",
      "[scrolling...] 2019/12/22 23:40\n"
     ]
    }
   ],
   "source": [
    "scroll_all_news(today_date)\n",
    "html_source = browser.page_source\n",
    "soup = BeautifulSoup(html_source, \"html5lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019/12/23 23:19</td>\n",
       "      <td>爆踹短髮正妹！酒醉男右胸遭刺穿噴血慘死…母崩潰：他本來要結婚生子</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019/12/23 23:17</td>\n",
       "      <td>快訊／國道台南驚傳火燒車　貨車撞起火「男子燒成焦屍」！全線封閉中</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019/12/23 23:08</td>\n",
       "      <td>尹立嗆聲：高雄50萬人不投韓！　指韓國瑜「遮羞布論」仇恨動員</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019/12/23 23:07</td>\n",
       "      <td>阿爆推排灣族語電音新作...遭叨念「舌頭不夠柔軟」！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019/12/23 23:03</td>\n",
       "      <td>李佳芬稱台灣災難「我們夫妻扛」　陳致中建議：請把韓國瑜扛回家</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>2019/12/23 00:14</td>\n",
       "      <td>影／更強「14°C冷空氣」將報到！巴逢颱風跑5天　周末雨襲全台變天</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>2019/12/23 00:11</td>\n",
       "      <td>CBA／劉錚爆發17分9籃板5助攻6抄截　廣廈終止三連敗</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>2019/12/23 00:10</td>\n",
       "      <td>秋冬大勢鎖定「#Almond Sugar糖杏仁棕」唇彩　氣質女孩選一支帶回家</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>2019/12/23 00:09</td>\n",
       "      <td>拍遺照拿「喪家名義」私下募款！殯葬紅人張軍凱被爆斂財　家屬知情氣炸</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>2019/12/23 00:00</td>\n",
       "      <td>尖沙咀強盜案求司法互助遭香港拒絕　法務部嘆「遺憾」</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>688 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date                                   title\n",
       "0    2019/12/23 23:19        爆踹短髮正妹！酒醉男右胸遭刺穿噴血慘死…母崩潰：他本來要結婚生子\n",
       "1    2019/12/23 23:17        快訊／國道台南驚傳火燒車　貨車撞起火「男子燒成焦屍」！全線封閉中\n",
       "2    2019/12/23 23:08          尹立嗆聲：高雄50萬人不投韓！　指韓國瑜「遮羞布論」仇恨動員\n",
       "3    2019/12/23 23:07              阿爆推排灣族語電音新作...遭叨念「舌頭不夠柔軟」！\n",
       "4    2019/12/23 23:03          李佳芬稱台灣災難「我們夫妻扛」　陳致中建議：請把韓國瑜扛回家\n",
       "..                ...                                     ...\n",
       "683  2019/12/23 00:14       影／更強「14°C冷空氣」將報到！巴逢颱風跑5天　周末雨襲全台變天\n",
       "684  2019/12/23 00:11            CBA／劉錚爆發17分9籃板5助攻6抄截　廣廈終止三連敗\n",
       "685  2019/12/23 00:10  秋冬大勢鎖定「#Almond Sugar糖杏仁棕」唇彩　氣質女孩選一支帶回家\n",
       "686  2019/12/23 00:09       拍遺照拿「喪家名義」私下募款！殯葬紅人張軍凱被爆斂財　家屬知情氣炸\n",
       "687  2019/12/23 00:00               尖沙咀強盜案求司法互助遭香港拒絕　法務部嘆「遺憾」\n",
       "\n",
       "[688 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infos_dict = {}\n",
    "infos_dict['date'] = []\n",
    "infos_dict['title'] = []\n",
    "\n",
    "for tag in soup.find(class_=\"part_list_2\").find_all('h3'):\n",
    "    tag_date = tag.find(class_=\"date\").text\n",
    "    tag_title = tag.find_all('a')[-1].text\n",
    "    \n",
    "    p = re.compile(\"(\\d+)/(\\d+)/(\\d+) (\\d+):(\\d+)\")\n",
    "    m = p.match(tag_date)\n",
    "    if m:\n",
    "        post_date_Y = int(m.group(1))\n",
    "        post_date_m = int(m.group(2))\n",
    "        post_date_d = int(m.group(3))\n",
    "        post_date_H = int(m.group(4))\n",
    "        post_date_M = int(m.group(5))\n",
    "            \n",
    "        post_date = datetime.datetime(post_date_Y,\n",
    "                                      post_date_m,\n",
    "                                      post_date_d,\n",
    "                                      post_date_H,\n",
    "                                      post_date_M)\n",
    "        if post_date.day == today_date.day:\n",
    "            #print(tag_date, tag_title)\n",
    "            infos_dict['date'].append(tag_date)\n",
    "            infos_dict['title'].append(tag_title)\n",
    "\n",
    "pd.DataFrame.from_dict(infos_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 取出今天下午三點到五點的新聞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYour Code\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Your Code\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019/12/23 17:59</td>\n",
       "      <td>聖誕版《瑪爾濟斯之歌》！全新MV＋洗腦歌詞笑爛網友：會背了啦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019/12/23 17:58</td>\n",
       "      <td>民眾黨新竹縣候選人林碩彥　「四大政見」要竹科榮耀再現</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019/12/23 17:58</td>\n",
       "      <td>湖人再戰快艇前「詹皇AD都爆傷情」　魔獸看聖誕大戰：冠軍是6月產生</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019/12/23 17:58</td>\n",
       "      <td>「我收到魚鉤⋯」！海洋生物聖誕交換禮物　藏人類垃圾殘害真相</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019/12/23 17:57</td>\n",
       "      <td>商業周刊／讓千人小村躍上國際的奢華菜單　西班牙味蕾再發現</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>2019/12/23 15:07</td>\n",
       "      <td>鄰居汪被小孩畫眉毛...抬頭變「兩津勘吉」！　深情表情笑翻網</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>2019/12/23 15:06</td>\n",
       "      <td>十口之家一餐只能花200元　32公斤長女心願：吃飽就好</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>2019/12/23 15:05</td>\n",
       "      <td>是時髦、更是性能休旅　Hyundai Kona、周裕穎攜手耀眼國際時尚圈</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>2019/12/23 15:04</td>\n",
       "      <td>尤里安／不再有效制敵？主戰車於城鎮戰的困境</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>2019/12/23 15:00</td>\n",
       "      <td>限量生蠔超鮮甜！台中新開平價日料　豚肉壽喜燒丼只要69元</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date                                 title\n",
       "0    2019/12/23 17:59        聖誕版《瑪爾濟斯之歌》！全新MV＋洗腦歌詞笑爛網友：會背了啦\n",
       "1    2019/12/23 17:58            民眾黨新竹縣候選人林碩彥　「四大政見」要竹科榮耀再現\n",
       "2    2019/12/23 17:58     湖人再戰快艇前「詹皇AD都爆傷情」　魔獸看聖誕大戰：冠軍是6月產生\n",
       "3    2019/12/23 17:58         「我收到魚鉤⋯」！海洋生物聖誕交換禮物　藏人類垃圾殘害真相\n",
       "4    2019/12/23 17:57          商業周刊／讓千人小村躍上國際的奢華菜單　西班牙味蕾再發現\n",
       "..                ...                                   ...\n",
       "183  2019/12/23 15:07        鄰居汪被小孩畫眉毛...抬頭變「兩津勘吉」！　深情表情笑翻網\n",
       "184  2019/12/23 15:06           十口之家一餐只能花200元　32公斤長女心願：吃飽就好\n",
       "185  2019/12/23 15:05  是時髦、更是性能休旅　Hyundai Kona、周裕穎攜手耀眼國際時尚圈\n",
       "186  2019/12/23 15:04                 尤里安／不再有效制敵？主戰車於城鎮戰的困境\n",
       "187  2019/12/23 15:00          限量生蠔超鮮甜！台中新開平價日料　豚肉壽喜燒丼只要69元\n",
       "\n",
       "[188 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infos_dict = {}\n",
    "infos_dict['date'] = []\n",
    "infos_dict['title'] = []\n",
    "\n",
    "for tag in soup.find(class_=\"part_list_2\").find_all('h3'):\n",
    "    tag_date = tag.find(class_=\"date\").text\n",
    "    tag_title = tag.find_all('a')[-1].text\n",
    "    \n",
    "    p = re.compile(\"(\\d+)/(\\d+)/(\\d+) (\\d+):(\\d+)\")\n",
    "    m = p.match(tag_date)\n",
    "    if m:\n",
    "        post_date_Y = int(m.group(1))\n",
    "        post_date_m = int(m.group(2))\n",
    "        post_date_d = int(m.group(3))\n",
    "        post_date_H = int(m.group(4))\n",
    "        post_date_M = int(m.group(5))\n",
    "            \n",
    "        post_date = datetime.datetime(post_date_Y,\n",
    "                                      post_date_m,\n",
    "                                      post_date_d,\n",
    "                                      post_date_H,\n",
    "                                      post_date_M)\n",
    "        if post_date.day == today_date.day and post_date.hour >= 15 and post_date.hour <= 17:            \n",
    "            infos_dict['date'].append(tag_date)\n",
    "            infos_dict['title'].append(tag_title)\n",
    "\n",
    "pd.DataFrame.from_dict(infos_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 根據範例，取出三天前下午三點到五點的新聞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYour Code\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Your Code\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[scrolling...] 2019/12/20 20:27\n",
      "[scrolling...] 2019/12/20 20:11\n",
      "[scrolling...] 2019/12/20 19:53\n",
      "[scrolling...] 2019/12/20 19:53\n",
      "[scrolling...] 2019/12/20 19:41\n",
      "[scrolling...] 2019/12/20 19:32\n",
      "[scrolling...] 2019/12/20 19:09\n",
      "[scrolling...] 2019/12/20 18:57\n",
      "[scrolling...] 2019/12/20 18:49\n",
      "[scrolling...] 2019/12/20 18:37\n",
      "[scrolling...] 2019/12/20 18:20\n",
      "[scrolling...] 2019/12/20 18:13\n",
      "[scrolling...] 2019/12/20 18:01\n",
      "[scrolling...] 2019/12/20 17:54\n",
      "[scrolling...] 2019/12/20 17:46\n",
      "[scrolling...] 2019/12/20 17:38\n",
      "[scrolling...] 2019/12/20 17:33\n",
      "[scrolling...] 2019/12/20 17:27\n",
      "[scrolling...] 2019/12/20 17:19\n",
      "[scrolling...] 2019/12/20 17:09\n",
      "[scrolling...] 2019/12/20 17:01\n",
      "[scrolling...] 2019/12/20 16:49\n",
      "[scrolling...] 2019/12/20 16:39\n",
      "[scrolling...] 2019/12/20 16:18\n",
      "[scrolling...] 2019/12/20 16:07\n",
      "[scrolling...] 2019/12/20 16:00\n",
      "[scrolling...] 2019/12/20 15:53\n",
      "[scrolling...] 2019/12/20 15:42\n",
      "[scrolling...] 2019/12/20 15:31\n",
      "[scrolling...] 2019/12/20 15:15\n",
      "[scrolling...] 2019/12/20 15:01\n",
      "[scrolling...] 2019/12/20 14:53\n",
      "[scrolling...] 2019/12/20 14:36\n",
      "[scrolling...] 2019/12/20 14:20\n",
      "[scrolling...] 2019/12/20 14:06\n",
      "[scrolling...] 2019/12/20 13:58\n",
      "[scrolling...] 2019/12/20 13:40\n",
      "[scrolling...] 2019/12/20 13:29\n",
      "[scrolling...] 2019/12/20 13:19\n",
      "[scrolling...] 2019/12/20 13:10\n",
      "[scrolling...] 2019/12/20 12:51\n",
      "[scrolling...] 2019/12/20 12:42\n",
      "[scrolling...] 2019/12/20 12:30\n",
      "[scrolling...] 2019/12/20 12:20\n",
      "[scrolling...] 2019/12/20 12:13\n",
      "[scrolling...] 2019/12/20 12:04\n",
      "[scrolling...] 2019/12/20 11:57\n",
      "[scrolling...] 2019/12/20 11:43\n",
      "[scrolling...] 2019/12/20 11:37\n",
      "[scrolling...] 2019/12/20 11:30\n",
      "[scrolling...] 2019/12/20 11:24\n",
      "[scrolling...] 2019/12/20 11:16\n",
      "[scrolling...] 2019/12/20 11:04\n",
      "[scrolling...] 2019/12/20 11:00\n",
      "[scrolling...] 2019/12/20 10:57\n",
      "[scrolling...] 2019/12/20 10:48\n",
      "[scrolling...] 2019/12/20 10:32\n",
      "[scrolling...] 2019/12/20 10:25\n",
      "[scrolling...] 2019/12/20 10:10\n",
      "[scrolling...] 2019/12/20 10:00\n",
      "[scrolling...] 2019/12/20 09:47\n",
      "[scrolling...] 2019/12/20 09:17\n",
      "[scrolling...] 2019/12/20 08:54\n",
      "[scrolling...] 2019/12/20 07:55\n",
      "[scrolling...] 2019/12/20 06:17\n",
      "[scrolling...] 2019/12/20 02:09\n",
      "[scrolling...] 2019/12/20 00:36\n",
      "[scrolling...] 2019/12/20 00:09\n",
      "[scrolling...] 2019/12/19 23:49\n"
     ]
    }
   ],
   "source": [
    "selected_date = today_date - datetime.timedelta(days=3)\n",
    "\n",
    "selectYear = Select(browser.find_element_by_id(\"selY\"))\n",
    "selectYear.select_by_value(str(selected_date.year))\n",
    "\n",
    "selectYear = Select(browser.find_element_by_id(\"selM\"))\n",
    "selectYear.select_by_value(str(selected_date.month))\n",
    "\n",
    "selectSite = Select(browser.find_element_by_id(\"selD\"))\n",
    "selectSite.select_by_value(str(selected_date.day))\n",
    "\n",
    "browser.find_element_by_id('button').click()\n",
    "\n",
    "scroll_all_news(selected_date)\n",
    "html_source = browser.page_source\n",
    "soup = BeautifulSoup(html_source, \"html5lib\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019/12/20 17:58</td>\n",
       "      <td>中職／彭政閔接班未來總教練　劉志威：找適當時間點</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019/12/20 17:58</td>\n",
       "      <td>蕭亞軒強勢回歸驚人樣貌曝光！　洩演唱會時間「明年生日起跑」</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019/12/20 17:56</td>\n",
       "      <td>前夫尿布丟臉掰惹！名醫黃宥嘉再掀戰　討「超奢華珠寶盒+135萬現鈔」結果出爐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019/12/20 17:55</td>\n",
       "      <td>城市躲貓貓　林智堅邀請大小朋友來發掘動物的秘密基地</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019/12/20 17:55</td>\n",
       "      <td>影／和尚用木魚敲「搖滾神曲」！魔性「咚咚~鏘」狂轟炸　一開口網全笑噴</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>2019/12/20 15:00</td>\n",
       "      <td>台灣第一雙金獎　陽獅媒體集團2019再創高峰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2019/12/20 15:00</td>\n",
       "      <td>澳門摘星之旅！搭星宇航空展開星級假期</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>2019/12/20 15:00</td>\n",
       "      <td>2020澳門新玩法！和星宇航空全台首架A321neo一起出發</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>2019/12/20 15:00</td>\n",
       "      <td>你與星宇航空最近的距離！1月23日台北澳門開航</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2019/12/20 15:00</td>\n",
       "      <td>咬下爆出湯汁！台中超夯鮮肉湯包　肉餡鮮甜、加辣更過癮</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date                                   title\n",
       "0    2019/12/20 17:58                中職／彭政閔接班未來總教練　劉志威：找適當時間點\n",
       "1    2019/12/20 17:58           蕭亞軒強勢回歸驚人樣貌曝光！　洩演唱會時間「明年生日起跑」\n",
       "2    2019/12/20 17:56  前夫尿布丟臉掰惹！名醫黃宥嘉再掀戰　討「超奢華珠寶盒+135萬現鈔」結果出爐\n",
       "3    2019/12/20 17:55               城市躲貓貓　林智堅邀請大小朋友來發掘動物的秘密基地\n",
       "4    2019/12/20 17:55      影／和尚用木魚敲「搖滾神曲」！魔性「咚咚~鏘」狂轟炸　一開口網全笑噴\n",
       "..                ...                                     ...\n",
       "176  2019/12/20 15:00                  台灣第一雙金獎　陽獅媒體集團2019再創高峰\n",
       "177  2019/12/20 15:00                      澳門摘星之旅！搭星宇航空展開星級假期\n",
       "178  2019/12/20 15:00          2020澳門新玩法！和星宇航空全台首架A321neo一起出發\n",
       "179  2019/12/20 15:00                 你與星宇航空最近的距離！1月23日台北澳門開航\n",
       "180  2019/12/20 15:00              咬下爆出湯汁！台中超夯鮮肉湯包　肉餡鮮甜、加辣更過癮\n",
       "\n",
       "[181 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infos_dict = {}\n",
    "infos_dict['date'] = []\n",
    "infos_dict['title'] = []\n",
    "\n",
    "for tag in soup.find(class_=\"part_list_2\").find_all('h3'):\n",
    "    tag_date = tag.find(class_=\"date\").text\n",
    "    tag_title = tag.find_all('a')[-1].text\n",
    "    \n",
    "    p = re.compile(\"(\\d+)/(\\d+)/(\\d+) (\\d+):(\\d+)\")\n",
    "    m = p.match(tag_date)\n",
    "    if m:\n",
    "        post_date_Y = int(m.group(1))\n",
    "        post_date_m = int(m.group(2))\n",
    "        post_date_d = int(m.group(3))\n",
    "        post_date_H = int(m.group(4))\n",
    "        post_date_M = int(m.group(5))\n",
    "            \n",
    "        post_date = datetime.datetime(post_date_Y,\n",
    "                                      post_date_m,\n",
    "                                      post_date_d,\n",
    "                                      post_date_H,\n",
    "                                      post_date_M)\n",
    "        if selected_date.day == selected_date.day and post_date.hour >= 15 and post_date.hour <= 17:            \n",
    "            infos_dict['date'].append(tag_date)\n",
    "            infos_dict['title'].append(tag_title)\n",
    "\n",
    "pd.DataFrame.from_dict(infos_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PCM",
   "language": "python",
   "name": "pcm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
